{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建clent\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key,base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fast language models are crucial for several reasons, impacting both user experience and practical applications:\\n\\n### 1. **Real-Time Interaction**  \\n   - **Conversational AI (Chatbots, Assistants):** Users expect instant responses in applications like customer support or virtual assistants (e.g., ChatGPT, Alexa). Delays disrupt the flow of conversation and reduce usability.  \\n   - **Gaming/NPCs:** Fast responses are needed for immersive interactions with AI-driven characters.  \\n\\n### 2. **Scalability & Cost Efficiency**  \\n   - **Lower Compute Costs:** Faster inference reduces the computational resources (and energy) required per query, making deployment cheaper at scale (e.g., for cloud services).  \\n   - **Higher Throughput:** Speed allows serving more users simultaneously without latency spikes, critical for apps with millions of users.  \\n\\n### 3. **Enhanced Productivity**  \\n   - **Coding Tools (Copilot, CodeLlama):** Developers rely on near-instant code suggestions to maintain workflow efficiency.  \\n   - **Content Creation:** Writers, marketers, or analysts using AI for drafts/edits need quick outputs to iterate rapidly.  \\n\\n### 4. **Edge/On-Device Deployment**  \\n   - **Mobile/Offline Use:** Faster, optimized models (e.g., TinyLLaMA) enable AI features on smartphones or IoT devices without relying on cloud latency.  \\n   - **Privacy:** Local processing avoids data transmission delays and security risks.  \\n\\n### 5. **Emergent Applications**  \\n   - **Autonomous Agents:** AI that controls robots, self-driving cars, or drones must process language inputs in milliseconds to act safely.  \\n   - **AR/VR:** Low-latency responses prevent motion sickness and improve immersion in AI-augmented environments.  \\n\\n### 6. **User Retention**  \\n   - Studies show users abandon tools with >2-second delays. Speed is a competitive advantage (e.g., Google’s search results vs. slower alternatives).  \\n\\n### **Trade-offs with Quality**  \\nWhile speed is vital, balancing it with accuracy is key. Techniques like model distillation, quantization, and efficient architectures (e.g., Mixtral’s sparse MoE) help maintain performance while reducing latency.  \\n\\nIn summary, fast language models unlock broader adoption, better user experiences, and cost-effective deployment—critical as AI integrates deeper into daily life.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[{\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client, system):\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    \n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        compiletion = self.client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        return compiletion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(operation) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    if planet == \"earth\":\n",
    "        return 5.972e24\n",
    "    if planet == \"mars\":\n",
    "        return 6.39e23\n",
    "    if planet == \"jupiter\":\n",
    "        return 1.898e27\n",
    "    if planet == \"saturn\":\n",
    "        return 5.683e26\n",
    "    if planet == \"uranus\":\n",
    "        return 8.681e25\n",
    "    if planet == \"neptune\":\n",
    "        return 1.024e26\n",
    "    if planet == \"mercury\":\n",
    "        return 3.285e23\n",
    "    if planet == \"venus\":\n",
    "        return 4.867e24\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_demo = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Mercury first.\n",
      "Action: get_planet_mass: Mercury\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = agent_demo(\"what is the mass of Mercury times 5\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285e+23\n"
     ]
    }
   ],
   "source": [
    "result = get_planet_mass(\"mercury\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 3.285e+23'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: Now I need to multiply the mass of Mercury by 5.\n",
      "Action: calculate: 3.285e+23 * 5\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = agent_demo(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6425e+24\n"
     ]
    }
   ],
   "source": [
    "result = calculate(\"3.285e+23 * 5\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 1.6425e+24'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The mass of Mercury times 5 is 1.6425e+24 kg.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_demo(next_prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "calculate:\n",
      "e.g. calculate: 4 * 7 / 3\n",
      "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
      "\n",
      "get_planet_mass:\n",
      "e.g. get_planet_mass: Earth\n",
      "returns weight of the planet in kg\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: What is the mass of Earth times 2?\n",
      "Thought: I need to find the mass of Earth\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE \n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: 5.972e24\n",
      "\n",
      "Thought: I need to multiply this by 2\n",
      "Action: calculate: 5.972e24 * 2\n",
      "PAUSE\n",
      "\n",
      "You will be called again with this: \n",
      "\n",
      "Observation: 1,1944×10e25\n",
      "\n",
      "If you have the answer, output it as the Answer.\n",
      "\n",
      "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
      "\n",
      "Now it's your turn:\n",
      "what is the mass of Mercury times 5\n",
      "Thought: I need to find the mass of Mercury first.\n",
      "Action: get_planet_mass: Mercury\n",
      "PAUSE\n",
      "Observation: 3.285e+23\n",
      "Thought: Now I need to multiply the mass of Mercury by 5.\n",
      "Action: calculate: 3.285e+23 * 5\n",
      "PAUSE\n",
      "Observation: 1.6425e+24\n",
      "Answer: The mass of Mercury times 5 is 1.6425e+24 kg.\n"
     ]
    }
   ],
   "source": [
    "for msg in agent_demo.messages:\n",
    "    print(msg['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
